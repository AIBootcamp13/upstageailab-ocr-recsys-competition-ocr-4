{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1J1TvAJQqV4YsGepz3N_KWY-zWIrzQ-ls","timestamp":1709019759006}],"gpuType":"T4","authorship_tag":"ABX9TyPLk35YrJv24wPTFlY5tHlN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f8e60ab5271149cf83af910df003189e":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"‚úî Done","disabled":true,"icon":"","layout":"IPY_MODEL_f09330497ca94e2086adbfe9dbb8c254","style":"IPY_MODEL_f301fd2044954fc99b824f4a841c7e2a","tooltip":""}},"f09330497ca94e2086adbfe9dbb8c254":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":"50px","object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f301fd2044954fc99b824f4a841c7e2a":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"12776edbe7cc4f088574e8be133dd831":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"success","description":"‚úî Done","disabled":true,"icon":"","layout":"IPY_MODEL_87c9f3c8b7254aeead1722fbf430d238","style":"IPY_MODEL_066a11b6ba974aaca5799b28fa10d94c","tooltip":""}},"87c9f3c8b7254aeead1722fbf430d238":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":"50px","object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"066a11b6ba974aaca5799b28fa10d94c":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}}},"cells":[{"cell_type":"markdown","source":["# **ÏòÅÏàòÏ¶ù Í∏ÄÏûê Í≤ÄÏ∂ú Baseline code Tutorial**\n","\n","\n","> ÏòÅÏàòÏ¶ù Í∏ÄÏûê Í≤ÄÏ∂ú ÎåÄÌöåÏóê Ïò§Ïã† Ïó¨Îü¨Î∂Ñ ÌôòÏòÅÌï©ÎãàÎã§! üéâ\n",">\n","> ÏïÑÎûò TutorialÏóêÏÑúÎäî Baseline codeÍ∞Ä Ïñ¥ÎñªÍ≤å Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÎäîÏßÄ ÏÇ¥Ìé¥Î≥¥Í≤†ÏäµÎãàÎã§.\n","\n","# Contents\n","\n","1.   Config Íµ¨ÏÑ±\n","2.   Model\n","3.   Lightning Module\n","4.   Train\n","5.   Test, Predict\n","6.   Tips\n","\n","---\n","‚ö†Ô∏è Ï£ºÏùòÏÇ¨Ìï≠\n","```\n","Tutorial ÌååÏùºÏùÄ Baseline codeÏùò Ïù¥Ìï¥Î•º ÎèïÍ∏∞ ÏúÑÌïú ÏòàÏ†úÎ°ú,\n","Google Colab ÌôòÍ≤ΩÏùÑ Í∏∞Ï§ÄÏúºÎ°ú ÏûëÏÑ±ÎêòÏñ¥ ÏûàÏäµÎãàÎã§.\n","VSCodeÎ•º Ïù¥Ïö©Ìïú Î°úÏª¨ ÌôòÍ≤ΩÏóêÏÑú Ïã§ÌñâÌï† Í≤ΩÏö∞ Í≤∞Î°ú ÏàòÏ†ï Îì±Ïù¥ ÌïÑÏöîÌï† Ïàò ÏûàÏäµÎãàÎã§.\n","```\n","---\n"],"metadata":{"id":"5VqAPknIoVE6"}},{"cell_type":"markdown","source":["# 0. Baseline code Îã§Ïö¥Î°úÎìú Î∞è Dependency ÏÑ§Ïπò\n","\n","Colab ÌôòÍ≤ΩÏóêÏÑú Baseline codeÎ•º Ïã§ÌñâÌïòÍ∏∞ ÏúÑÌïú ÏÑ§Ï†ïÏûÖÎãàÎã§."],"metadata":{"id":"6sxjE00Psk4M"}},{"cell_type":"code","source":["#@markdown ### Colab ÎÖ∏Ìä∏Î∂Å Dependency ÏÑ§ÏπòÌïòÍ∏∞\n","#@markdown - Colab ÎÖ∏Ìä∏Î∂ÅÏùÑ ÏÇ¨Ïö©ÌïòÎäîÎç∞ ÌïÑÏöîÌïú PackagesÎ•º ÏÑ§ÏπòÌï©ÎãàÎã§.\n","#@markdown ---\n","\n","from IPython.display import clear_output\n","import ipywidgets as widgets\n","\n","def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n","C_default = \"\\033[0;39m\"\n","C_yellow = \"\\033[1;93m\"\n","\n","print(C_yellow + \"Install...\" + C_default)\n","# START\n","\n","!pip install gdown==v4.6.3 pathlib==1.0.1\n","\n","# END CODE\n","clear_output()\n","inf('\\u2714 Done', 'success', '50px')"],"metadata":{"cellView":"form","id":"7GQ0Y9Vqt0Dx","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["f8e60ab5271149cf83af910df003189e","f09330497ca94e2086adbfe9dbb8c254","f301fd2044954fc99b824f4a841c7e2a"]},"executionInfo":{"status":"ok","timestamp":1709024899858,"user_tz":-540,"elapsed":8558,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"d58edeb7-6c75-41f2-983e-6d8bf32c7290"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='‚úî Done', disabled=True, layout=Layout(min_width='50px'), style=But‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8e60ab5271149cf83af910df003189e"}},"metadata":{}}]},{"cell_type":"code","source":["#@markdown ### Baseline code Îã§Ïö¥Î°úÎìú (Google Drive)\n","\n","#@markdown ÎØ∏Î¶¨ Ï§ÄÎπÑÎêú Îã§Ïùå ÌååÏùºÏùÑ ÏÑ§Ï†ïÌïú Í≤ΩÎ°úÏóê Îã§Ïö¥Î°úÎìú Î∞õÏäµÎãàÎã§.\n","#@markdown - Baseline code\n","#@markdown - Test dataset\n","#@markdown - Model checkpoint\n","#@markdown ---\n","\n","print(C_yellow + \"Download...\" + C_default)\n","# START\n","\n","from pathlib import Path\n","\n","Baseline_URL = \"https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000293/data/code.tar.gz\" #@param {type:\"string\"}\n","Library_URL = \"https://drive.google.com/drive/folders/1TYvjiTivRJcIrLytshcEaaooLie9s4pU?usp=sharing\" #@param {type:\"string\"}\n","Dataset_URL = \"https://drive.google.com/drive/folders/1FBEafD3Zua86kb5TodVUgAk5SgRuIUJ4?usp=sharing\" #@param {type:\"string\"}\n","Download_Path = Path('/content')\n","\n","Baseline_Path = Download_Path / \"baseline_code\"\n","Library_Path = Baseline_Path / \"lib\"\n","Dataset_Path = Download_Path / \"dataset\"\n","\n","!mkdir -p {Download_Path}\n","!curl -o {Download_Path}/code.tar.gz {Baseline_URL}\n","!gdown {Library_URL} -O {Library_Path} --folder\n","!gdown {Dataset_URL} -O {Dataset_Path} --folder\n","\n","!mkdir -p /data\n","!ln -s /content/dataset /data/datasets\n","\n","print(C_yellow + \"Install...\" + C_default)\n","!tar xvfz {Download_Path}/code.tar.gz\n","!pip install -r {Library_Path}/requirements.txt\n","!cp -rf {Library_Path}/vgg16.py {Baseline_Path}/ocr/models/encoder/\n","\n","%cd {Baseline_Path}\n","\n","# END CODE\n","clear_output()\n","inf('\\u2714 Done', 'success', '50px')"],"metadata":{"id":"9UhwsQXmuEJx","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["12776edbe7cc4f088574e8be133dd831","87c9f3c8b7254aeead1722fbf430d238","066a11b6ba974aaca5799b28fa10d94c"]},"outputId":"1f86754b-c47b-4207-ead6-d30850e37d9c","cellView":"form","executionInfo":{"status":"ok","timestamp":1709024928692,"user_tz":-540,"elapsed":28838,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Button(button_style='success', description='‚úî Done', disabled=True, layout=Layout(min_width='50px'), style=But‚Ä¶"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12776edbe7cc4f088574e8be133dd831"}},"metadata":{}}]},{"cell_type":"code","source":["#@markdown ### GPU ÏÇ¨Ïö© ÏÑ§Ï†ï\n","\n","#@markdown - Colab ÌôòÍ≤ΩÏóêÏÑú Ïú†Ìö®Ìïú DeviceÎ•º ÌôïÏù∏Ìï©ÎãàÎã§.\n","#@markdown ---\n","\n","import torch\n","\n","def to_device(data, device):\n","    if isinstance(data, (list, tuple)):\n","        return [to_device(x, device) for x in data]\n","    elif isinstance(data, dict):\n","        return {k: to_device(v, device) for k, v in data.items()}\n","    elif isinstance(data, torch.Tensor):\n","        return data.to(device)\n","    else:\n","        return data\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(f'Use [{device}]')"],"metadata":{"cellView":"form","id":"BEvjbfj7Lgxe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024930810,"user_tz":-540,"elapsed":2131,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"f26fd3e9-7a2d-4c87-8607-65e32a58dd83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Use [cuda]\n"]}]},{"cell_type":"markdown","source":["# 1. Config Íµ¨ÏÑ±\n","\n","Config Íµ¨ÏÑ±ÏùÄ Hydra Í∏∞Î∞òÏúºÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÏúºÎ©∞ ÏïÑÎûòÏôÄ Í∞ôÏùÄ Folder structureÎ•º Í∞ÄÏßëÎãàÎã§.\n","\n","```\n","‚îî‚îÄ‚îÄ‚îÄ configs\n","    ‚îú‚îÄ‚îÄ preset\n","    ‚îÇ   ‚îú‚îÄ‚îÄ example.yaml\n","    ‚îÇ   ‚îú‚îÄ‚îÄ base.yaml\n","    ‚îÇ   ‚îú‚îÄ‚îÄ datasets\n","    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db.yaml\n","    ‚îÇ   ‚îú‚îÄ‚îÄ lightning_modules\n","    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.yaml\n","    ‚îÇ   ‚îú‚îÄ‚îÄ metrics\n","    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cleval.yaml\n","    ‚îÇ   ‚îî‚îÄ‚îÄ models\n","    ‚îÇ       ‚îú‚îÄ‚îÄ decoder\n","    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ unet.yaml\n","    ‚îÇ       ‚îú‚îÄ‚îÄ encoder\n","    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ timm_backbone.yaml\n","    ‚îÇ       ‚îú‚îÄ‚îÄ head\n","    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ db_head.yaml\n","    ‚îÇ       ‚îú‚îÄ‚îÄ loss\n","    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ db_loss.yaml\n","    ‚îÇ       ‚îú‚îÄ‚îÄ postprocess\n","    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ base.yaml\n","    ‚îÇ       ‚îî‚îÄ‚îÄ model_example.yaml\n","    ‚îú‚îÄ‚îÄ train.yaml\n","    ‚îú‚îÄ‚îÄ test.yaml\n","    ‚îî‚îÄ‚îÄ predict.yaml\n"," ```"],"metadata":{"id":"H11g2Tq-pCJS"}},{"cell_type":"markdown","source":["## 1.1 Dataset config\n","\n","- configs/preset/datasets/db.yaml\n","\n","> Dataset configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê.\n","\n","```yaml\n","# @package _global_\n","\n","dataset_base_path: \"/data/datasets/\"   # Change your path\n","\n","datasets:\n","  train_dataset:\n","    _target_: ${dataset_path}.OCRDataset\n","    image_path: ${dataset_base_path}images/train\n","    annotation_path: ${dataset_base_path}jsons/train.json\n","    transform: ${transforms.train_transform}\n","  val_dataset:\n","    _target_: ${dataset_path}.OCRDataset\n","    image_path: ${dataset_base_path}images/val\n","    annotation_path: ${dataset_base_path}jsons/val.json\n","    transform: ${transforms.val_transform}\n","  test_dataset:\n","    _target_: ${dataset_path}.OCRDataset\n","    image_path: ${dataset_base_path}images/val\n","    annotation_path: ${dataset_base_path}jsons/val.json\n","    transform: ${transforms.test_transform}\n","  predict_dataset:\n","    _target_: ${dataset_path}.OCRDataset\n","    image_path: ${dataset_base_path}images/test\n","    annotation_path: null\n","    transform: ${transforms.test_transform}\n","\n","transforms:\n","  train_transform:\n","    _target_: ${dataset_path}.DBTransforms\n","    transforms:\n","      - _target_: albumentations.LongestMaxSize\n","        max_size: 640\n","        p: 1.0\n","      - _target_: albumentations.PadIfNeeded\n","        min_width: 640\n","        min_height: 640\n","        border_mode: 0\n","        p: 1.0\n","      - _target_: albumentations.HorizontalFlip\n","        p: 0.5\n","      - _target_: albumentations.Normalize\n","        mean: [0.485, 0.456, 0.406]\n","        std: [0.229, 0.224, 0.225]\n","    keypoint_params:\n","      _target_: albumentations.KeypointParams\n","      format: 'xy'\n","      remove_invisible: True\n","```"],"metadata":{"id":"HZDgbkGLp084"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"36Nh0KVFoQPF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024934094,"user_tz":-540,"elapsed":3286,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"75b3cca7-a215-4414-9cfa-ee0ba84429e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['image', 'image_filename', 'shape', 'polygons', 'inverse_matrix'])"]},"metadata":{},"execution_count":4}],"source":["import omegaconf\n","from pathlib import Path\n","from hydra.utils import instantiate\n","import sys\n","from hydra import compose, initialize\n","\n","sys.path.append(str(Baseline_Path))\n","\n","config_path = 'configs/'\n","\n","with initialize(version_base=None, config_path=str(config_path), job_name=\"test_app\"):\n","    cfg = compose(config_name=\"train\", overrides=[\"preset=example\"])\n","\n","train_dataset = instantiate(cfg.datasets.train_dataset)\n","\n","data = train_dataset[0]\n","data.keys()"]},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","dataloaders:\n","  train_dataloader:\n","    batch_size: 4\n","    shuffle: True\n","    num_workers: 2\n","  val_dataloader:\n","    batch_size: 4\n","    shuffle: False\n","    num_workers: 2\n","  test_dataloader:\n","    batch_size: 4\n","    shuffle: False\n","    num_workers: 2\n","  predict_dataloader:\n","    batch_size: 1\n","    shuffle: False\n","    num_workers: 2\n","\n","collate_fn:\n","  _target_: ${dataset_path}.DBCollateFN\n","  shrink_ratio: 0.4\n","  thresh_min: 0.3\n","  thresh_max: 0.7\n","```"],"metadata":{"id":"u_ADx1sNkHD_"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","collate_fn = instantiate(cfg.collate_fn)\n","collate_fn.inference_mode = False\n","data_loader = DataLoader(train_dataset, collate_fn=collate_fn, **cfg.dataloaders.train_dataloader)\n","for i, data_loaded in enumerate(data_loader):\n","    if i == 1:\n","        break\n","    print(data_loaded.keys())\n","    print(f\"image size: {data_loaded['images'].shape}\")\n","\n","data_loaded = to_device(data_loaded, device)"],"metadata":{"id":"2oznAglYkX1g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024935363,"user_tz":-540,"elapsed":1272,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"99e1a1f0-5d3d-4be8-b58f-5cdb14c404b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["odict_keys(['images', 'image_filename', 'inverse_matrix', 'polygons', 'prob_maps', 'thresh_maps'])\n","image size: torch.Size([4, 3, 640, 640])\n"]}]},{"cell_type":"markdown","source":["## 1.2 Encoder config\n","\n","- configs/preset/models/encoder/timm_backbone.yaml\n","\n","Encoder - Decoder - Head Íµ¨Ï°∞ Ï§ë Encoder configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"QNfRu8tdlv1v"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","models:\n","  encoder:\n","    _target_: ${encoder_path}.TimmBackbone\n","    model_name: 'resnet18'\n","    select_features: [1, 2, 3, 4]            # Output layer\n","    pretrained: true\n","```"],"metadata":{"id":"kvAzQzTrmgCo"}},{"cell_type":"code","source":["encoder = instantiate(cfg.models.encoder).to(device)\n","encoder_features = encoder(data_loaded[\"images\"])\n","for encoder_feature in encoder_features:\n","    print(encoder_feature.shape)"],"metadata":{"id":"z4nbvMaRlvUL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024938910,"user_tz":-540,"elapsed":3549,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"328353f2-176b-4df1-c6bd-8abf4a17ddfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 64, 160, 160])\n","torch.Size([4, 128, 80, 80])\n","torch.Size([4, 256, 40, 40])\n","torch.Size([4, 512, 20, 20])\n"]}]},{"cell_type":"markdown","source":["## 1.3 Decoder config\n","\n","- configs/preset/models/decoder/unet.yaml\n","\n","Encoder - Decoder - Head Íµ¨Ï°∞ Ï§ë Decoder configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"7cKE_ScDoa8U"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","models:\n","  decoder:\n","    _target_: ${decoder_path}.UNet\n","    in_channels: [64, 128, 256, 512]  # Input layer channel\n","    strides: [4, 8, 16, 32]           # Input layer scale\n","    inner_channels: 256               # Hidden layer channel\n","    output_channels: 64               # output layer channel\n","    bias: False\n","```"],"metadata":{"id":"5S4KnhUcolpy"}},{"cell_type":"code","source":["decoder = instantiate(cfg.models.decoder).to(device)\n","decoder_features = decoder(encoder_features)\n","for decoder_feature in decoder_features:\n","    print(decoder_feature.shape)"],"metadata":{"id":"OiADLRQVoqw2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024939295,"user_tz":-540,"elapsed":387,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"78ac3c38-726a-4968-a370-183505a0b615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 64, 160, 160])\n","torch.Size([4, 64, 160, 160])\n","torch.Size([4, 64, 160, 160])\n","torch.Size([4, 64, 160, 160])\n"]}]},{"cell_type":"markdown","source":["## 1.4 Head config\n","\n","- configs/preset/models/head/db_head.yaml\n","\n","Encoder - Decoder - Head Íµ¨Ï°∞ Ï§ë Head configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"n3Fvcj_Ro6kA"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","# https://arxiv.org/pdf/1911.08947.pdf Ï∞∏Ï°∞\n","\n","models:\n","  head:\n","    _target_: ${head_path}.DBHead\n","    in_channels: 256                 # Input layer channel\n","    upscale: 4                       # Output layer scale factor\n","    k: 50                            # The amplifying factor\n","    bias: False                      # Use bias or not in LayerNorm\n","    smooth: False                    # Use smooth or not in Upsample\n","    postprocess:\n","      thresh: 0.3                    # Binarization threshold\n","      box_thresh: 0.7                # Detection Box threshold\n","      max_candidates: 300            # Limit the number of detection boxes\n","      use_polygon: False             # Detection Box Type (QUAD or POLY)\n","```"],"metadata":{"id":"NRMk0VjcpCd0"}},{"cell_type":"code","source":["head = instantiate(cfg.models.head).to(device)\n","with torch.no_grad():\n","  head_output = head(decoder_features)\n","  for k, v in head_output.items():\n","      print(f'{k}: {v.shape}')"],"metadata":{"id":"sxyu9ce5pFUC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024939617,"user_tz":-540,"elapsed":324,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"dace3301-bfd3-4ebc-b6c7-a39d53772b8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["prob_maps: torch.Size([4, 1, 640, 640])\n","thresh_maps: torch.Size([4, 1, 640, 640])\n","binary_maps: torch.Size([4, 1, 640, 640])\n"]}]},{"cell_type":"markdown","source":["## 1.5 Loss config\n","\n","- configs/preset/models/loss/db_loss.yaml\n","\n","Loss configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"_F1F1u5VpaQw"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","# https://arxiv.org/pdf/1911.08947.pdf Ï∞∏Ï°∞\n","\n","models:\n","  loss:\n","    _target_: ${loss_path}.DBLoss\n","    negative_ratio: 3.0\n","    eps: 1e-6\n","    prob_map_loss_weight: 5.0\n","    thresh_map_loss_weight: 10.0\n","    binary_map_loss_weight: 1.0\n","```"],"metadata":{"id":"mrEHcrv7ph2Y"}},{"cell_type":"code","source":["loss_fn = instantiate(cfg.models.loss).to(device)\n","loss, loss_dict = loss_fn(head_output, **data_loaded)\n","print(loss)\n","for k, v in loss_dict.items():\n","    print(f'{k}: {v}')"],"metadata":{"id":"BfvzJVtEpZ4y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024940365,"user_tz":-540,"elapsed":750,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"faebfcd6-e0ef-4225-8c90-149260dd0ce9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(30.8433, device='cuda:0')\n","loss_prob: 5.339261531829834\n","loss_thresh: 0.322316437959671\n","loss_binary: 0.9238760471343994\n"]}]},{"cell_type":"markdown","source":["## 1.6 Post Process\n","\n","Model outputÏùÑ ÌõÑÏ≤òÎ¶¨ÌïòÎ©¥ Ïñ¥Îñ†Ìïú outputÏù¥ ÎÇòÏò§ÎäîÏßÄ ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"RCucSOrUqOMK"}},{"cell_type":"code","source":["boxes_batch, boxes_score = head.get_polygons_from_maps(data_loaded, head_output)"],"metadata":{"id":"xbIWP5Z0qDke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["boxes_batch"],"metadata":{"id":"Nt8YqdOzqP26","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024942053,"user_tz":-540,"elapsed":5,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"48beea4d-4245-4386-bf37-6476fa6df02c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[[[840, 1264], [866, 1264], [866, 1280], [840, 1280]],\n","  [[1102, 1264], [1114, 1264], [1114, 1274], [1102, 1274]],\n","  [[978, 1260], [988, 1270], [979, 1279], [969, 1269]],\n","  [[969, 1261], [979, 1271], [970, 1280], [960, 1270]],\n","  [[952, 1254], [972, 1264], [964, 1280], [944, 1270]],\n","  [[946, 1258], [956, 1268], [947, 1277], [937, 1267]],\n","  [[920, 1260], [931, 1271], [922, 1280], [911, 1269]],\n","  [[904, 1270], [914, 1260], [922, 1268], [912, 1278]],\n","  [[904, 1260], [915, 1271], [906, 1280], [895, 1269]],\n","  [[895, 1260], [907, 1268], [897, 1282], [885, 1274]],\n","  [[888, 1260], [898, 1270], [889, 1279], [879, 1269]],\n","  [[880, 1260], [890, 1270], [881, 1279], [871, 1269]],\n","  [[858, 1262], [882, 1262], [882, 1278], [858, 1278]],\n","  [[794, 1262], [818, 1262], [818, 1280], [794, 1280]],\n","  [[792, 1260], [803, 1271], [794, 1280], [783, 1269]],\n","  [[600, 1260], [611, 1271], [602, 1280], [591, 1269]],\n","  [[592, 1260], [603, 1271], [594, 1280], [583, 1269]],\n","  [[356, 1264], [366, 1264], [366, 1276], [356, 1276]],\n","  [[236, 1262], [260, 1262], [260, 1280], [236, 1280]]],\n"," [],\n"," [],\n"," [[[1110, 1264], [1120, 1264], [1120, 1276], [1110, 1276]],\n","  [[1102, 1264], [1114, 1264], [1114, 1274], [1102, 1274]],\n","  [[934, 1268], [958, 1256], [966, 1272], [942, 1284]],\n","  [[857, 1259], [868, 1270], [859, 1279], [848, 1268]],\n","  [[834, 1262], [858, 1262], [858, 1280], [834, 1280]],\n","  [[720, 1270], [730, 1260], [738, 1268], [728, 1278]],\n","  [[720, 1260], [731, 1271], [722, 1280], [711, 1269]],\n","  [[704, 1270], [714, 1260], [722, 1268], [712, 1278]],\n","  [[572, 1264], [586, 1264], [586, 1278], [572, 1278]],\n","  [[564, 1264], [578, 1264], [578, 1278], [564, 1278]],\n","  [[561, 1259], [572, 1270], [563, 1279], [552, 1268]],\n","  [[538, 1260], [550, 1272], [540, 1282], [528, 1270]],\n","  [[530, 1260], [540, 1270], [530, 1280], [520, 1270]],\n","  [[522, 1260], [532, 1270], [522, 1280], [512, 1270]],\n","  [[514, 1260], [524, 1270], [514, 1280], [504, 1270]],\n","  [[490, 1260], [500, 1270], [490, 1280], [480, 1270]],\n","  [[481, 1259], [492, 1270], [483, 1279], [472, 1268]],\n","  [[462, 1252], [480, 1270], [464, 1286], [446, 1268]],\n","  [[450, 1260], [460, 1270], [450, 1280], [440, 1270]],\n","  [[386, 1260], [396, 1270], [386, 1280], [376, 1270]],\n","  [[370, 1260], [380, 1270], [370, 1280], [360, 1270]],\n","  [[346, 1260], [356, 1270], [346, 1280], [336, 1270]],\n","  [[230, 1260], [318, 1260], [318, 1282], [230, 1282]],\n","  [[152, 1260], [192, 1260], [192, 1282], [152, 1282]],\n","  [[-2, 1264], [8, 1264], [8, 1276], [-2, 1276]],\n","  [[677, 1261], [711, 1255], [715, 1279], [681, 1285]]]]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["boxes_score"],"metadata":{"id":"wF0Ov7ggqTdI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709024942054,"user_tz":-540,"elapsed":5,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"3f35a4e8-04e1-4eb1-9591-9961cd3a8a62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.45524825815111397,\n","  0.6496775825893565,\n","  0.5841146866839967,\n","  0.4793402031799288,\n","  0.5766175248995856,\n","  0.6665217394107266,\n","  0.4715702997577451,\n","  0.5163349043448558,\n","  0.4439139825259417,\n","  0.47516152241761345,\n","  0.5143326961386169,\n","  0.5864490897302845,\n","  0.5763864548336844,\n","  0.49151017881787856,\n","  0.5251596476092263,\n","  0.45600231226953014,\n","  0.46975141108288715,\n","  0.5906513050547801,\n","  0.523324312770927],\n"," [],\n"," [],\n"," [0.7143274578265846,\n","  0.6290705460545724,\n","  0.47780686336541706,\n","  0.41646984848656843,\n","  0.40017052990447993,\n","  0.5309884444706969,\n","  0.5799044613329236,\n","  0.5308339078910649,\n","  0.4260425598886286,\n","  0.4338377337550628,\n","  0.4682258974734892,\n","  0.45017589119242984,\n","  0.48015375061968374,\n","  0.4544194877299015,\n","  0.4410321581177414,\n","  0.4702468290552497,\n","  0.4168512431298785,\n","  0.46145283357291195,\n","  0.48142035766039043,\n","  0.46864132285350935,\n","  0.46602760212146677,\n","  0.4363943788292818,\n","  0.41702349438673997,\n","  0.44712691594112486,\n","  0.513532528722135,\n","  0.449682647100014]]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## 1.7 Model config\n","\n","- configs/preset/models/model_example.yaml\n","\n","Encoder - Decoder - Head - LossÎ•º Ìï©Ïπú Model configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"_ZnxUXKoqgyB"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","defaults:\n","  - /preset/models/decoder/unet\n","  - /preset/models/encoder/timm_backbone\n","  - /preset/models/head/db_head\n","  - /preset/models/loss/db_loss\n","  - _self_\n","\n","models:\n","  optimizer:\n","    _target_: torch.optim.Adam\n","    lr: 0.001\n","    weight_decay: 0.0001\n","  scheduler:\n","    _target_: torch.optim.lr_scheduler.StepLR\n","    step_size: 100\n","    gamma: 0.1\n","```"],"metadata":{"id":"VbKucQL_qx0X"}},{"cell_type":"markdown","source":["## 1.8 Example config\n","\n","- configs/preset/example.yaml\n","\n","Dataset, Model, Base setting configÎ•º Ìï©Ïπú Example config"],"metadata":{"id":"n5Pc3HwIrEfc"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","defaults:\n","  - base\n","  - /preset/datasets/db\n","  - /preset/models/model_example\n","  - /preset/lightning_modules/base\n","  - _self_\n","```"],"metadata":{"id":"X64UDatKrF4K"}},{"cell_type":"markdown","source":["## 1.9 Train config\n","\n","- configs/train.yaml\n","\n","Train Í¥ÄÎ†® configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"AOPVmyDQrND3"}},{"cell_type":"markdown","source":["```yaml\n","defaults:\n","  - _self_\n","  - preset:\n","  - override hydra/hydra_logging: disabled\n","  - override hydra/job_logging: disabled\n","\n","seed: 42\n","exp_name: \"ocr_training\"\n","project_name: \"OCRProject\"\n","\n","wandb: False\n","exp_version: \"v1.0\"\n","\n","resume: null  # \"checkpoints/sehwan_20240118_144938/epoch=5-step=4908.ckpt\"\n","\n","trainer:\n","  max_epochs: 10\n","  num_sanity_val_steps: 1\n","  log_every_n_steps: 50\n","  check_val_every_n_epoch: 1\n","  deterministic: True\n","```"],"metadata":{"id":"lvS5yebQrVch"}},{"cell_type":"markdown","source":["## 1.10 Test config\n","\n","- configs/test.yaml\n","\n","Test Í¥ÄÎ†® configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"VJSXft17rn_P"}},{"cell_type":"markdown","source":["```yaml\n","defaults:\n","  - _self_\n","  - preset:\n","  - override hydra/hydra_logging: disabled\n","  - override hydra/job_logging: disabled\n","\n","seed: 42\n","exp_name: \"ocr_training\"\n","project_name: \"OCRProject\"\n","\n","wandb: False\n","exp_version: \"v1.0\"\n","\n","checkpoint_path: \"checkpoints/sehwan_20240118_144938/epoch=5-step=4908.ckpt\"\n","```"],"metadata":{"id":"23sUSDhHruRC"}},{"cell_type":"markdown","source":["## 1.11 Predict config\n","\n","- configs/predict.yaml\n","\n","Predict Í¥ÄÎ†® configÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"9GD-XZXWsBcK"}},{"cell_type":"markdown","source":["```yaml\n","defaults:\n","  - _self_\n","  - preset:\n","  - override hydra/hydra_logging: disabled\n","  - override hydra/job_logging: disabled\n","\n","seed: 42\n","exp_name: \"ocr_training\"\n","\n","checkpoint_path: \"checkpoints/sehwan_20240118_144938/epoch=5-step=4908.ckpt\"\n","minified_json: False\n","```"],"metadata":{"id":"6-soCKdbsFu7"}},{"cell_type":"markdown","source":["# 2. Model\n","\n","ModelÏùò Íµ¨ÌòÑÏ≤¥Îäî Ïñ¥ÎñªÍ≤å ÏÉùÍ≤ºÎäîÏßÄ ÏïåÏïÑÎ≥¥Ïûê.\n","\n","1.   Encoder\n","2.   Decoder\n","3.   Architecture\n","\n"],"metadata":{"id":"Ou37itr0sNxA"}},{"cell_type":"markdown","source":["## 2.1 Encoder"],"metadata":{"id":"muoxgk-8sZyP"}},{"cell_type":"code","source":["import torch.nn as nn\n","import timm\n","\n","\n","class TimmBackbone(nn.Module):\n","    def __init__(self, model_name='resnet18', select_features=[1, 2, 3, 4], pretrained=True):\n","        super(TimmBackbone, self).__init__()\n","        # Timm Backbone Î™®Îç∏ÏùÑ ÏûêÏú†Î°≠Í≤å ÏÇ¨Ïö©\n","        self.model = timm.create_model(model_name, pretrained=pretrained, features_only=True)\n","        # DecoderÏóê Ïó∞Í≤∞ÌïòÎ†§Îäî FeatureÎ•º ÏÑ†ÌÉù\n","        self.select_features = select_features\n","\n","    def forward(self, x):\n","        features = self.model(x)\n","        return [features[i] for i in self.select_features]"],"metadata":{"id":"UpBxd8Hlscd1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Decoder"],"metadata":{"id":"Rrv63B9Asler"}},{"cell_type":"code","source":["from itertools import accumulate\n","import torch.nn as nn\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self,\n","                 in_channels=[64, 128, 256, 512],\n","                 strides=[4, 8, 16, 32],\n","                 inner_channels=256,\n","                 output_channels=64,\n","                 bias=False):\n","        super(UNet, self).__init__()\n","\n","        assert len(strides) == len(in_channels), \"Mismatch in 'strides' and 'in_channels' lengths.\"\n","\n","        # ParametersÏóê Îî∞Îùº UNet Íµ¨Ï°∞Î•º ÎèôÏ†ÅÏúºÎ°ú ÏÉùÏÑ±\n","        # Decoder size Í≥ÑÏÇ∞\n","        upscale_factors = [strides[idx] // strides[idx - 1] for idx in range(1, len(strides))]\n","        outscale_factors = list(accumulate(upscale_factors, lambda x, y: x * y))\n","\n","        self.upsamples = nn.ModuleList()\n","        for upscale in upscale_factors:\n","            self.upsamples.append(nn.Upsample(scale_factor=upscale, mode='nearest'))\n","\n","        self.inners = nn.ModuleList()\n","        for in_channel in in_channels:\n","            self.inners.append(nn.Conv2d(in_channel, inner_channels, kernel_size=1, bias=bias))\n","\n","        self.outers = nn.ModuleList()\n","        for outscale in reversed(outscale_factors):\n","            outer = nn.Sequential(nn.Conv2d(inner_channels, output_channels,\n","                                            kernel_size=3, padding=1, bias=bias),\n","                                  nn.Upsample(scale_factor=outscale, mode='nearest'))\n","            self.outers.append(outer)\n","        self.outers.append(nn.Conv2d(inner_channels, output_channels, kernel_size=3,\n","                                     padding=1, bias=bias))\n","\n","        self.upsamples.apply(self.weights_init)\n","        self.inners.apply(self.weights_init)\n","        self.outers.apply(self.weights_init)\n","\n","    def weights_init(self, m):\n","        classname = m.__class__.__name__\n","        if classname.find('Conv') != -1:\n","            nn.init.kaiming_normal_(m.weight.data)\n","        elif classname.find('BatchNorm') != -1:\n","            m.weight.data.fill_(1.)\n","            m.bias.data.fill_(1e-4)\n","\n","    def forward(self, features):\n","        in_features = [inner(feat) for feat, inner in zip(features, self.inners)]\n","\n","        up_features = []\n","        up = in_features[-1]\n","        for i in range(len(in_features) - 1, 0, -1):\n","            up = self.upsamples[i - 1](up) + in_features[i - 1]\n","            up_features.append(up)\n","\n","        out_features = [self.outers[0](in_features[-1])]\n","        out_features += [outer(feat) for feat, outer in zip(up_features, self.outers[1:])]\n","\n","        return out_features"],"metadata":{"id":"ZMXNqTensumU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 Architecture"],"metadata":{"id":"HwSmcsErsyR_"}},{"cell_type":"code","source":["import torch.nn as nn\n","from hydra.utils import instantiate\n","from ocr.models.encoder import get_encoder_by_cfg\n","from ocr.models.decoder import get_decoder_by_cfg\n","from ocr.models.head import get_head_by_cfg\n","from ocr.models.loss import get_loss_by_cfg\n","\n","\n","class OCRModel(nn.Module):\n","    def __init__(self, cfg):\n","        super(OCRModel, self).__init__()\n","        self.cfg = cfg\n","\n","        # Í∞Å Î™®Îìà instantiate\n","        self.encoder = get_encoder_by_cfg(cfg.encoder)\n","        self.decoder = get_decoder_by_cfg(cfg.decoder)\n","        self.head = get_head_by_cfg(cfg.head)\n","        self.loss = get_loss_by_cfg(cfg.loss)\n","\n","    def forward(self, images, return_loss=True, **kwargs):\n","        encoded_features = self.encoder(images)\n","        decoded_features = self.decoder(encoded_features)\n","        pred = self.head(decoded_features, return_loss)\n","\n","        # Loss Í≥ÑÏÇ∞\n","        if return_loss:\n","            loss, loss_dict = self.loss(pred, **kwargs)\n","            pred.update(loss=loss, loss_dict=loss_dict)\n","\n","        return pred\n","\n","    def get_optimizers(self):\n","        optimizer_config = self.cfg.optimizer\n","        optimizer = instantiate(optimizer_config, params=self.parameters())\n","\n","        if 'scheduler' in self.cfg:\n","            scheduler_config = self.cfg.scheduler\n","            scheduler = instantiate(scheduler_config, optimizer=optimizer)\n","            return [optimizer], [scheduler]\n","        return optimizer\n","\n","    def get_polygons_from_maps(self, gt, pred):\n","        return self.head.get_polygons_from_maps(gt, pred)"],"metadata":{"id":"6lm4hh-Ss0S1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Lightning Module\n","\n","LightningÏùò ModuleÏóê ÎåÄÌï¥ÏÑú ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"Hz5k-9W9s_ke"}},{"cell_type":"markdown","source":["## 3.1 Lightning Trainer"],"metadata":{"id":"n6s6GJ4TtHUX"}},{"cell_type":"code","source":["import numpy as np\n","import json\n","from datetime import datetime\n","from pathlib import Path\n","import lightning.pytorch as pl\n","from tqdm import tqdm\n","from collections import defaultdict\n","from collections import OrderedDict\n","from torch.utils.data import DataLoader\n","from hydra.utils import instantiate\n","from ocr.metrics import CLEvalMetric\n","\n","\n","class OCRPLModule(pl.LightningModule):\n","    def __init__(self, model, dataset, config):\n","        super(OCRPLModule, self).__init__()\n","        self.model = model\n","        self.dataset = dataset\n","        self.metric = CLEvalMetric()\n","        self.config = config\n","\n","        self.validation_step_outputs = OrderedDict()\n","        self.test_step_outputs = OrderedDict()\n","        self.predict_step_outputs = OrderedDict()\n","\n","    def forward(self, x):\n","        return self.model(return_loss=False, **x)\n","\n","    def training_step(self, batch, batch_idx):\n","        pred = self.model(**batch)\n","        self.log('train/loss', pred['loss'], batch_size=len(batch))\n","        for key, value in pred['loss_dict'].items():\n","            self.log(f'train/{key}', value, batch_size=len(batch))\n","        return pred\n","\n","    def validation_step(self, batch, batch_idx):\n","        pred = self.model(**batch)\n","        self.log('val/loss', pred['loss'], batch_size=len(batch))\n","        for key, value in pred['loss_dict'].items():\n","            self.log(f'val/{key}', value, batch_size=len(batch))\n","\n","        boxes_batch, _ = self.model.get_polygons_from_maps(batch, pred)\n","        for idx, boxes in enumerate(boxes_batch):\n","            self.validation_step_outputs[batch['image_filename'][idx]] = boxes\n","        return pred\n","\n","    def on_validation_epoch_end(self):\n","        cleval_metrics = defaultdict(list)\n","\n","        for gt_filename, gt_words in tqdm(self.dataset['val'].anns.items(), desc=\"Evaluation\"):\n","            if gt_filename not in self.validation_step_outputs:\n","                # TODO: Check if this is on_sanity?\n","                cleval_metrics['recall'].append(np.array(0., dtype=np.float32))\n","                cleval_metrics['precision'].append(np.array(0., dtype=np.float32))\n","                cleval_metrics['hmean'].append(np.array(0., dtype=np.float32))\n","                continue\n","\n","            pred = self.validation_step_outputs[gt_filename]\n","            det_quads = [[point for coord in polygons for point in coord]\n","                         for polygons in pred]\n","            gt_quads = [item.squeeze().reshape(-1) for item in gt_words]\n","\n","            self.metric(det_quads, gt_quads)\n","            cleval = self.metric.compute()\n","            cleval_metrics['recall'].append(cleval['det_r'].cpu().numpy())\n","            cleval_metrics['precision'].append(cleval['det_p'].cpu().numpy())\n","            cleval_metrics['hmean'].append(cleval['det_h'].cpu().numpy())\n","            self.metric.reset()\n","\n","        recall = np.mean(cleval_metrics['recall'])\n","        precision = np.mean(cleval_metrics['precision'])\n","        hmean = np.mean(cleval_metrics['hmean'])\n","\n","        self.log('val/recall', recall, on_epoch=True, prog_bar=True)\n","        self.log('val/precision', precision, on_epoch=True, prog_bar=True)\n","        self.log('val/hmean', hmean, on_epoch=True, prog_bar=True)\n","\n","        self.validation_step_outputs.clear()\n","\n","    def test_step(self, batch):\n","        pred = self.model(return_loss=False, **batch)\n","\n","        boxes_batch, _ = self.model.get_polygons_from_maps(batch, pred)\n","        for idx, boxes in enumerate(boxes_batch):\n","            self.test_step_outputs[batch['image_filename'][idx]] = boxes\n","        return pred\n","\n","    def on_test_epoch_end(self):\n","        cleval_metrics = defaultdict(list)\n","\n","        for gt_filename, gt_words in tqdm(self.dataset['test'].anns.items(), desc=\"Evaluation\"):\n","            pred = self.test_step_outputs[gt_filename]\n","            det_quads = [[point for coord in polygons for point in coord]\n","                         for polygons in pred]\n","            gt_quads = [item.squeeze().reshape(-1) for item in gt_words]\n","\n","            self.metric(det_quads, gt_quads)\n","            cleval = self.metric.compute()\n","            cleval_metrics['recall'].append(cleval['det_r'].cpu().numpy())\n","            cleval_metrics['precision'].append(cleval['det_p'].cpu().numpy())\n","            cleval_metrics['hmean'].append(cleval['det_h'].cpu().numpy())\n","            self.metric.reset()\n","\n","        recall = np.mean(cleval_metrics['recall'])\n","        precision = np.mean(cleval_metrics['precision'])\n","        hmean = np.mean(cleval_metrics['hmean'])\n","\n","        self.log('test/recall', recall, on_epoch=True, prog_bar=True)\n","        self.log('test/precision', precision, on_epoch=True, prog_bar=True)\n","        self.log('test/hmean', hmean, on_epoch=True, prog_bar=True)\n","\n","        self.test_step_outputs.clear()\n","\n","    def predict_step(self, batch):\n","        pred = self.model(return_loss=False, **batch)\n","        boxes_batch, _ = self.model.get_polygons_from_maps(batch, pred)\n","\n","        for idx, boxes in enumerate(boxes_batch):\n","            self.predict_step_outputs[batch['image_filename'][idx]] = boxes\n","        return pred\n","\n","    def on_predict_epoch_end(self):\n","        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        submission_file = Path(f\"{self.config.submission_dir}\") / f\"{timestamp}.json\"\n","        submission_file.parent.mkdir(parents=True, exist_ok=True)\n","\n","        submission = OrderedDict(images=OrderedDict())\n","        for filename, pred_boxes in self.predict_step_outputs.items():\n","            # Separate box\n","            boxes = OrderedDict()\n","            for idx, box in enumerate(pred_boxes):\n","                boxes[f'{idx + 1:04}'] = OrderedDict(points=box)\n","\n","            # Append box\n","            submission['images'][filename] = OrderedDict(words=boxes)\n","\n","        # Export submission\n","        with submission_file.open(\"w\") as fp:\n","            if self.config.minified_json:\n","                json.dump(submission, fp, indent=None, separators=(',', ':'))\n","            else:\n","                json.dump(submission, fp, indent=4)\n","\n","        self.predict_step_outputs.clear()\n","\n","    def configure_optimizers(self):\n","        return self.model.get_optimizers()"],"metadata":{"id":"XaRmUtNwtLWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 Lightning Data Module"],"metadata":{"id":"1dt6O5Y6tb2j"}},{"cell_type":"code","source":["class OCRDataPLModule(pl.LightningDataModule):\n","    def __init__(self, dataset, config):\n","        super(OCRDataPLModule, self).__init__()\n","        self.dataset = dataset\n","        self.config = config\n","        self.collate_fn = instantiate(self.config.collate_fn)\n","\n","    def train_dataloader(self):\n","        train_loader_config = self.config.dataloaders.train_dataloader\n","        self.collate_fn.inference_mode = False\n","        return DataLoader(self.dataset['train'], collate_fn=self.collate_fn, **train_loader_config)\n","\n","    def val_dataloader(self):\n","        val_loader_config = self.config.dataloaders.val_dataloader\n","        self.collate_fn.inference_mode = False\n","        return DataLoader(self.dataset['val'], collate_fn=self.collate_fn, **val_loader_config)\n","\n","    def test_dataloader(self):\n","        test_loader_config = self.config.dataloaders.test_dataloader\n","        self.collate_fn.inference_mode = False\n","        return DataLoader(self.dataset['test'], collate_fn=self.collate_fn, **test_loader_config)\n","\n","    def predict_dataloader(self):\n","        predict_loader_config = self.config.dataloaders.predict_dataloader\n","        self.collate_fn.inference_mode = True\n","        return DataLoader(self.dataset['predict'], collate_fn=self.collate_fn,\n","                          **predict_loader_config)"],"metadata":{"id":"0PbpSe4ttiY3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Train\n","\n","Î™ÖÎ†πÏñ¥Î•º ÌÜµÌï¥ Ïñ¥ÎñªÍ≤å ÌïôÏäµÏùÑ ÏãúÌÇ¨ Ïàò ÏûàÎäîÏßÄ, ÌïôÏäµ Ïã§Ìñâ ÏΩîÎìúÎäî Ïñ¥ÎñªÍ≤å Ïù¥Î£®Ïñ¥Ï†∏ ÏûàÎäîÏßÄ ÏïåÏïÑÎ≥¥Ïûê"],"metadata":{"id":"qfl2TLTftmKD"}},{"cell_type":"code","source":["!python runners/train.py preset=example"],"metadata":{"id":"SAjLN_8ntt3z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025000257,"user_tz":-540,"elapsed":56296,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"4d4c54f9-de91-451c-c245-8458b0df9d42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-27 09:09:14.631496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-27 09:09:14.631547: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-27 09:09:14.632930: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-27 09:09:15.746780: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /content/baseline_code/outputs/ocr_training/checkpoints exists and is not empty.\n","Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Sanity Checking DataLoader 0: 100% 1/1 [00:01<00:00,  1.38s/it]\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n","Evaluation:  25% 1/4 [00:00<00:01,  2.01it/s]\u001b[A\n","Evaluation: 100% 4/4 [00:00<00:00,  5.64it/s]\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","Epoch 0: 100% 1/1 [00:01<00:00,  1.35s/it, v_num=v1.0]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.11it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  25% 1/4 [00:00<00:01,  1.91it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00,  3.58it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00,  5.07it/s]\n","\n","Epoch 1:   0% 0/1 [00:00<?, ?it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Epoch 1: 100% 1/1 [00:01<00:00,  1.18s/it, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.03it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 17.35it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 14.86it/s]\n","\n","Epoch 2: 100% 1/1 [00:01<00:00,  1.01s/it, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.98it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 16.78it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 14.68it/s]\n","\n","Epoch 3: 100% 1/1 [00:00<00:00,  1.08it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.77it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00,  3.18it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00,  5.18it/s]\n","\n","Epoch 4: 100% 1/1 [00:00<00:00,  1.07it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.23it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 11.71it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 10.10it/s]\n","\n","Epoch 5: 100% 1/1 [00:01<00:00,  1.33s/it, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.66it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 17.29it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 15.69it/s]\n","\n","Epoch 6: 100% 1/1 [00:00<00:00,  1.08it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.68it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 17.36it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 15.17it/s]\n","\n","Epoch 7: 100% 1/1 [00:00<00:00,  1.01it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.74it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 16.48it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 14.29it/s]\n","\n","Epoch 8: 100% 1/1 [00:00<00:00,  1.00it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  1.23it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00,  9.82it/s]\u001b[A\u001b[A\n","\n","Evaluation:  75% 3/4 [00:00<00:00,  8.11it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00,  8.70it/s]\n","\n","Epoch 9: 100% 1/1 [00:00<00:00,  1.02it/s, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n","Validation:   0% 0/1 [00:00<?, ?it/s]        \u001b[A\n","Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0: 100% 1/1 [00:00<00:00,  2.16it/s]\u001b[A\n","\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluation:  50% 2/4 [00:00<00:00, 15.74it/s]\u001b[A\u001b[A\n","\n","Evaluation: 100% 4/4 [00:00<00:00, 14.13it/s]\n","\n","Epoch 9: 100% 1/1 [00:03<00:00,  3.26s/it, v_num=v1.0, val/recall=0.000, val/precision=0.000, val/hmean=0.000]\n","Testing DataLoader 0: 100% 1/1 [00:00<00:00,  2.07it/s]\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n","Evaluation:  50% 2/4 [00:00<00:00, 15.52it/s]\u001b[A\n","Evaluation: 100% 4/4 [00:00<00:00, 13.64it/s]\n","Testing DataLoader 0: 100% 1/1 [00:00<00:00,  1.27it/s]\n","‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ\u001b[36m \u001b[0m\u001b[36m       test/hmean        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m‚îÇ\n","‚îÇ\u001b[36m \u001b[0m\u001b[36m     test/precision      \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m‚îÇ\n","‚îÇ\u001b[36m \u001b[0m\u001b[36m       test/recall       \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"]}]},{"cell_type":"markdown","source":["```yaml\n","defaults:\n","  - _self_\n","  - preset: example\n","  - override hydra/hydra_logging: disabled\n","  - override hydra/job_logging: disabled\n","\n","seed: 42\n","exp_name: \"ocr_training\"\n","project_name: \"OCRProject\"\n","\n","wandb: False\n","exp_version: \"v1.0\"\n","\n","resume: null  # \"checkpoints/sehwan_20240118_144938/epoch=5-step=4908.ckpt\"\n","\n","trainer:\n","  max_epochs: 10\n","  num_sanity_val_steps: 1\n","  log_every_n_steps: 50\n","  check_val_every_n_epoch: 1\n","  deterministic: True\n","```"],"metadata":{"id":"mrdKJCHDwgUK"}},{"cell_type":"markdown","source":["```python\n","@hydra.main(config_path=CONFIG_DIR, config_name='train', version_base='1.2')\n","def train(config):\n","    model_module, data_module = get_pl_modules_by_cfg(config)\n","\n","    trainer = pl.Trainer(\n","        **config.trainer,\n","        logger=logger,\n","        callbacks=callbacks\n","    )\n","\n","    trainer.fit(\n","        model_module,\n","        data_module,\n","        ckpt_path=config.get(\"resume\", None),\n","    )\n","    trainer.test(\n","        model_module,\n","        data_module,\n","    )\n","\n","\n","if __name__ == \"__main__\":\n","    train()\n","```"],"metadata":{"id":"f-83-XYUxVBE"}},{"cell_type":"markdown","source":["# 5. Test, Predict\n","\n","Î™ÖÎ†πÏñ¥Î•º ÌÜµÌï¥ÏÑú Test, PredictÎäî Ïñ¥ÎñªÍ≤å ÌïòÎäîÏßÄ, Test, Predict Ïã§Ìñâ ÏΩîÎìúÎäî Ïñ¥ÎñªÍ≤å Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÎäîÏßÄ ÏïåÏïÑÎ≥¥Ïûê."],"metadata":{"id":"sSknxhPixhw_"}},{"cell_type":"code","source":["!python runners/test.py preset=example \"checkpoint_path='lib/dbnet-baseline.ckpt'\""],"metadata":{"id":"FUREmcNGxW-F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025018194,"user_tz":-540,"elapsed":17951,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"d31da6eb-dae1-4bd2-a9af-133145109269"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-27 09:10:08.461757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-27 09:10:08.461833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-27 09:10:08.463237: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-27 09:10:09.776315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Testing DataLoader 0: 100% 1/1 [00:00<00:00,  2.16it/s]\n","Evaluation:   0% 0/4 [00:00<?, ?it/s]\u001b[A\n","Evaluation:  25% 1/4 [00:01<00:03,  1.14s/it]\u001b[A\n","Evaluation:  50% 2/4 [00:01<00:01,  1.47it/s]\u001b[A\n","Evaluation:  75% 3/4 [00:02<00:00,  1.62it/s]\u001b[A\n","Evaluation: 100% 4/4 [00:02<00:00,  1.65it/s]\n","Testing DataLoader 0: 100% 1/1 [00:02<00:00,  2.91s/it]\n","‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n","‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n","‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n","‚îÇ\u001b[36m \u001b[0m\u001b[36m       test/hmean        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.7507498264312744    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n","‚îÇ\u001b[36m \u001b[0m\u001b[36m     test/precision      \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.9591268301010132    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n","‚îÇ\u001b[36m \u001b[0m\u001b[36m       test/recall       \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.6375572681427002    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n","‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"]}]},{"cell_type":"markdown","source":["```python\n","@hydra.main(config_path=CONFIG_DIR, config_name='test', version_base='1.2')\n","def test(config):\n","    model_module, data_module = get_pl_modules_by_cfg(config)\n","\n","    trainer = pl.Trainer(\n","        logger=logger,\n","    )\n","\n","    trainer.test(\n","        model_module,\n","        data_module,\n","        ckpt_path=config.get(\"checkpoint_path\", None),\n","    )\n","\n","\n","if __name__ == \"__main__\":\n","    test()\n","```"],"metadata":{"id":"S44AMxzizIEs"}},{"cell_type":"code","source":["!python runners/predict.py preset=example \"checkpoint_path='lib/dbnet-baseline.ckpt'\""],"metadata":{"id":"kzsr21Bcza6J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025028860,"user_tz":-540,"elapsed":10679,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"64be9a86-2b6b-416e-fdb7-281b49b7697c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Predicting DataLoader 0: 100% 4/4 [00:00<00:00,  6.38it/s]\n"]}]},{"cell_type":"markdown","source":["```python\n","@hydra.main(config_path=CONFIG_DIR, config_name='predict', version_base='1.2')\n","def predict(config):\n","    model_module, data_module = get_pl_modules_by_cfg(config)\n","\n","    trainer = pl.Trainer()\n","\n","    pred = trainer.predict(model_module,\n","                           data_module,\n","                           ckpt_path=config.get(\"checkpoint_path\"),\n","                           )\n","\n","\n","if __name__ == \"__main__\":\n","    predict()\n","```"],"metadata":{"id":"xicnuBtNzdHI"}},{"cell_type":"code","source":["#@markdown ### Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n","\n","#@markdown - ÎØ∏ÏÇ¨Ïö© ÏûêÏõêÏùÑ Î∞òÌôòÌïòÍ≥† Î©îÎ™®Î¶¨Î•º ÌôïÎ≥¥Ìï©ÎãàÎã§.\n","#@markdown ---\n","\n","import gc\n","\n","try:\n","  if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","  del encoder\n","  del decoder\n","  del head\n","  del head_output\n","  del loss_fn\n","\n","  gc.collect()\n","\n","  print(\"Clear!\")\n","\n","except:\n","  pass"],"metadata":{"cellView":"form","id":"q6jOsm2kSWua","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025028861,"user_tz":-540,"elapsed":14,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"adb422f0-07a5-4c42-b48b-32708efb18f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clear!\n"]}]},{"cell_type":"markdown","source":["# 6. Tips\n","\n","1.   Logging\n","2.   Encoder ÍµêÏ≤¥\n","3.   Decoder ÍµêÏ≤¥\n","4.   Head ÍµêÏ≤¥\n","5.   Dataset augmentation\n","6.   ÌõÑÏ≤òÎ¶¨ Í≥†ÎèÑÌôî\n","7.   Customize model\n","\n"],"metadata":{"id":"rD92Nl9rzzmJ"}},{"cell_type":"markdown","source":["## 6.1 Logging"],"metadata":{"id":"mPhgNoWe0Buo"}},{"cell_type":"markdown","source":["```bash\n","!python runners/train.py preset=example exp_name=sehwan wandb=True\n","\n","# https://wandb.ai/sehwan-joo_up/OCRProject?workspace=user-sehwan-joo_up\n","```"],"metadata":{"id":"Io5A32UW28fp"}},{"cell_type":"markdown","source":["```bash\n","!python runners/train.py preset=example exp_name=sehwan wandb=False\n","!tensorboard --log_dirs={logging_path} --port={port_number}\n","```"],"metadata":{"id":"s2N0I62r2sYC"}},{"cell_type":"markdown","source":["## 6.2 Encoder ÍµêÏ≤¥"],"metadata":{"id":"mn1Xv77D3D9J"}},{"cell_type":"code","source":["import torch.nn as nn\n","import timm\n","\n","\n","class TimmBackbone(nn.Module):\n","    def __init__(self, model_name='resnet18', select_features=[1, 2, 3, 4], pretrained=True):\n","        super(TimmBackbone, self).__init__()\n","        # Timm Backbone Î™®Îç∏ÏùÑ ÏûêÏú†Î°≠Í≤å ÏÇ¨Ïö©\n","        self.model = timm.create_model(model_name, pretrained=pretrained, features_only=True)\n","        # DecoderÏóê Ïó∞Í≤∞ÌïòÎ†§Îäî FeatureÎ•º ÏÑ†ÌÉù\n","        self.select_features = select_features\n","\n","    def forward(self, x):\n","        features = self.model(x)\n","        return [features[i] for i in self.select_features]"],"metadata":{"id":"RJIQog9j3RJr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","models:\n","  encoder:\n","    _target_: ${encoder_path}.TimmBackbone\n","    model_name: 'convnext_pico.d1_in1k'   #resnet18\n","    select_features: [1, 2, 3, 4]            # Output layer\n","    pretrained: true\n","```"],"metadata":{"id":"bW84fCwz3W-a"}},{"cell_type":"code","source":["cfg.models.encoder.model_name = 'convnext_pico.d1_in1k'\n","\n","encoder = instantiate(cfg.models.encoder).to(device)\n","encoder_features = encoder(data_loaded[\"images\"])\n","for encoder_feature in encoder_features:\n","    print(encoder_feature.shape)"],"metadata":{"id":"Wi6QsPX93xGg","colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"status":"error","timestamp":1709025029855,"user_tz":-540,"elapsed":1006,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"eed6dc45-aff6-46cf-b093-85d67297acff"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-873685c04d60>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoder_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mencoder_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoder_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/baseline_code/ocr/models/encoder/timm_backbone.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/baseline_code/ocr/models/encoder/timm_backbone.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":["for feature in encoder.model(data_loaded[\"images\"]):\n","    print(feature.shape)"],"metadata":{"id":"71kQnD4c4YWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025080206,"user_tz":-540,"elapsed":269,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"c6ae3811-54f6-42f3-f902-a285caf7ba30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 64, 160, 160])\n","torch.Size([4, 128, 80, 80])\n","torch.Size([4, 256, 40, 40])\n","torch.Size([4, 512, 20, 20])\n"]}]},{"cell_type":"code","source":["cfg.models.encoder.model_name = 'convnext_pico.d1_in1k'\n","cfg.models.encoder.select_features = [0, 1, 2, 3]\n","\n","encoder = instantiate(cfg.models.encoder).to(device)\n","encoder_features = encoder(data_loaded[\"images\"])\n","for encoder_feature in encoder_features:\n","    print(encoder_feature.shape)"],"metadata":{"id":"oT_5FLAt4ka7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025080985,"user_tz":-540,"elapsed":326,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"09c85a4d-3550-4f86-abc0-558613f2f01c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 64, 160, 160])\n","torch.Size([4, 128, 80, 80])\n","torch.Size([4, 256, 40, 40])\n","torch.Size([4, 512, 20, 20])\n"]}]},{"cell_type":"markdown","source":["## 6.3 Decoder ÍµêÏ≤¥"],"metadata":{"id":"AzipOwip5HNc"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","models:\n","  decoder:\n","    _target_: ${decoder_path}.UNet\n","    in_channels: [64, 128, 256, 512]  # [64, 128, 256, 512]\n","    strides: [4, 8, 16, 32]           # [4, 8, 16, 32]\n","    inner_channels: 256               # Hidden layer channel\n","    output_channels: 64               # output layer channel\n","    bias: False\n","```"],"metadata":{"id":"Lwk8HB4v5KDx"}},{"cell_type":"code","source":["cfg.models.decoder.in_channels = [64, 128, 256, 512]\n","cfg.models.decoder.strides = [4, 8, 16, 32]\n","decoder = instantiate(cfg.models.decoder).to(device)\n","decoder_features = decoder(encoder_features)\n","for decoder_feature in decoder_features:\n","    print(decoder_feature.shape)"],"metadata":{"id":"zaAkahgp6IHl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025083281,"user_tz":-540,"elapsed":296,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"064b32d6-c40a-482b-e611-5e3226829100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 64, 160, 160])\n","torch.Size([4, 64, 160, 160])\n","torch.Size([4, 64, 160, 160])\n","torch.Size([4, 64, 160, 160])\n"]}]},{"cell_type":"code","source":["cfg.models.decoder.output_channels = 256\n","decoder = instantiate(cfg.models.decoder).to(device)\n","decoder_features = decoder(encoder_features)\n","for decoder_feature in decoder_features:\n","    print(decoder_feature.shape)"],"metadata":{"id":"rVZ1MPJM6Stc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025085179,"user_tz":-540,"elapsed":374,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"e8494301-9ebd-4580-b912-52d38f7db7fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 256, 160, 160])\n","torch.Size([4, 256, 160, 160])\n","torch.Size([4, 256, 160, 160])\n","torch.Size([4, 256, 160, 160])\n"]}]},{"cell_type":"markdown","source":["## 6.4 Head ÍµêÏ≤¥"],"metadata":{"id":"CHwMcwJB6eWh"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","# https://arxiv.org/pdf/1911.08947.pdf Ï∞∏Ï°∞\n","\n","models:\n","  head:\n","    _target_: ${head_path}.DBHead\n","    in_channels: 1024                # 256\n","    upscale: 4                       # 4\n","    k: 50                            # The amplifying factor\n","    bias: False                      # Use bias or not in LayerNorm\n","    smooth: False                    # Use smooth or not in Upsample\n","    postprocess:\n","      thresh: 0.3                    # Binarization threshold\n","      box_thresh: 0.7                # Detection Box threshold\n","      max_candidates: 300            # Limit the number of detection boxes\n","      use_polygon: False             # Detection Box Type (QUAD or POLY)\n","```"],"metadata":{"id":"4YpyZs2j6jDD"}},{"cell_type":"code","source":["cfg.models.head.in_channels = 256 * 4\n","cfg.models.head.upscale = 4\n","\n","head = instantiate(cfg.models.head).to(device)\n","with torch.no_grad():\n","  head_output = head(decoder_features)\n","  for k, v in head_output.items():\n","      print(f'{k}: {v.shape}')"],"metadata":{"id":"ONuzBQi263wV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025087672,"user_tz":-540,"elapsed":382,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"59b74bb4-dd1c-449e-aaf3-f9a79d8c4e53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["prob_maps: torch.Size([4, 1, 640, 640])\n","thresh_maps: torch.Size([4, 1, 640, 640])\n","binary_maps: torch.Size([4, 1, 640, 640])\n"]}]},{"cell_type":"code","source":["#@markdown ### Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n","\n","#@markdown - ÎØ∏ÏÇ¨Ïö© ÏûêÏõêÏùÑ Î∞òÌôòÌïòÍ≥† Î©îÎ™®Î¶¨Î•º ÌôïÎ≥¥Ìï©ÎãàÎã§.\n","#@markdown ---\n","\n","import gc\n","\n","try:\n","  if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","  del encoder\n","  del encoder_features\n","  del decoder\n","  del decoder_features\n","  del head\n","  del head_output\n","\n","  gc.collect()\n","\n","  print(\"Clear!\")\n","\n","except:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"ONwgIDFZmU6x","executionInfo":{"status":"ok","timestamp":1709025090949,"user_tz":-540,"elapsed":365,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"9bdd5b40-5626-43ab-8610-d20baf3c78e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clear!\n"]}]},{"cell_type":"markdown","source":["## 6.5 Dataset augmentation"],"metadata":{"id":"u7b8BGEd7FnC"}},{"cell_type":"markdown","source":["```yaml\n","transforms:\n","  train_transform:\n","    _target_: ${dataset_path}.DBTransforms\n","    transforms:\n","      - _target_: albumentations.LongestMaxSize\n","        max_size: 640\n","        p: 1.0\n","      - _target_: albumentations.PadIfNeeded\n","        min_width: 640\n","        min_height: 640\n","        border_mode: 0\n","        p: 1.0\n","      - _target_: albumentations.HorizontalFlip\n","        p: 0.5\n","      - _target_: albumentations.Normalize\n","        mean: [0.485, 0.456, 0.406]\n","        std: [0.229, 0.224, 0.225]\n","      - _target_: albumentations.ShiftScaleRotate    # Ï∂îÍ∞ÄÎêú augmentation\n","        shift_limit: 0.5\n","        scale_limit: (0.5, 1.0)\n","    keypoint_params:\n","      _target_: albumentations.KeypointParams\n","      format: 'xy'\n","      remove_invisible: True\n","```"],"metadata":{"id":"p2S-CA-x7Nmz"}},{"cell_type":"code","source":["cfg.transforms.train_transform.transforms.append(\n","    omegaconf.OmegaConf.create(\n","        dict(\n","            _target_='albumentations.ShiftScaleRotate',\n","            shift_limit=0.5,\n","            scale_limit=(0.5, 1.0)\n","        )\n","    )\n",")\n","train_dataset = instantiate(cfg.datasets.train_dataset)\n","\n","data = train_dataset[0]\n","data.keys()"],"metadata":{"id":"-x19vqEQ7OkG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025094096,"user_tz":-540,"elapsed":306,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"ff96e576-e2d5-478b-8202-c13b130ce081"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['image', 'image_filename', 'shape', 'polygons', 'inverse_matrix'])"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["## 6.6 ÌõÑÏ≤òÎ¶¨ Í≥†ÎèÑÌôî"],"metadata":{"id":"i9-ZAMpc8Mo_"}},{"cell_type":"markdown","source":["```yaml\n","# @package _global_\n","\n","# https://arxiv.org/pdf/1911.08947.pdf Ï∞∏Ï°∞\n","\n","models:\n","  head:\n","    _target_: ${head_path}.DBHead\n","    in_channels: 256                 # Input layer channel\n","    upscale: 4                       # Output layer scale factor\n","    k: 50                            # The amplifying factor\n","    bias: False                      # Use bias or not in LayerNorm\n","    smooth: False                    # Use smooth or not in Upsample\n","    postprocess:\n","      thresh: 0.2                    # 0.3\n","      box_thresh: 0.3                # 0.4\n","      max_candidates: 1000           # 300\n","      use_polygon: True              # False\n","```"],"metadata":{"id":"Up3NFg8-8O3L"}},{"cell_type":"code","source":["cfg.models.head.postprocess.thresh = 0.2\n","cfg.models.head.postprocess.box_thresh = 0.3\n","cfg.models.head.postprocess.max_candidates = 1000\n","cfg.models.head.postprocess.use_polygon = True"],"metadata":{"id":"QZaBXnc_8ncH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6.7 Customize model\n","\n","EncoderÎ•º ÏòàÏãúÎ°ú Custom\n","\n","ÏïÑÎûòÏùò ÏòàÏãú ÌÅ¥ÎûòÏä§Î•º ocr/models/encoder/ Ìè¥Îçî ÏïÑÎûòÏóê ÏÉùÏÑ±"],"metadata":{"id":"dNbWsU1F-cgI"}},{"cell_type":"code","source":["import torch\n","\n","def conv_layer(chann_in, chann_out, k_size, p_size):\n","    layer = torch.nn. Sequential(\n","        torch.nn.Conv2d(chann_in, chann_out, kernel_size=k_size, padding=p_size),\n","        torch.nn.BatchNorm2d(chann_out),\n","        torch.nn.ReLU()\n","    )\n","    return layer\n","\n","def vgg_conv_block(in_list, out_list, k_list, p_list, pooling_k, pooling_s):\n","    layers = [ conv_layer(in_list[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_list)) ]\n","    layers += [ torch.nn.MaxPool2d(kernel_size = pooling_k, stride = pooling_s) ]\n","    return torch.nn.Sequential(*layers)\n","\n","def vgg_fc_layer(size_in, size_out) :\n","    layer = torch.nn.Sequential(\n","        torch.nn.Linear(size_in, size_out),\n","        torch.nn.BatchNormld(size_out),\n","        torch.nn.ReLU()\n","    )\n","    return layer\n","\n","class VGG16(torch.nn.Module):\n","    def __init__(self):\n","        super(VGG16, self).__init__()\n","\n","        # Conv blocks (BatchNorm + ReLU activation added in each block)\n","        self.layer1 = vgg_conv_block([3,64], [64,64], [3,3], [1,1], 2, 2)\n","        self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)\n","        self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)\n","        self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n","        self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n","\n","    def forward(self, x):\n","        features = [self.layer1(x)]\n","        features.append(self.layer2(features[-1]))\n","        features.append(self.layer3(features[-1]))\n","        features.append(self.layer4(features[-1]))\n","        features.append(self.layer5(features[-1]))\n","\n","        return features"],"metadata":{"id":"mGK03Yap-pBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg_encoder = VGG16().to(device)\n","vgg_output = vgg_encoder(data_loaded[\"images\"])\n","for v in vgg_output:\n","    print (v.shape)"],"metadata":{"id":"GqFxPdRGXvhl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025104312,"user_tz":-540,"elapsed":260,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"d6b05b59-90dc-423f-d2a1-6ea5cdb75895"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 64, 320, 320])\n","torch.Size([4, 128, 160, 160])\n","torch.Size([4, 256, 80, 80])\n","torch.Size([4, 512, 40, 40])\n","torch.Size([4, 512, 20, 20])\n"]}]},{"cell_type":"code","source":["#@markdown ### Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n","\n","#@markdown - ÎØ∏ÏÇ¨Ïö© ÏûêÏõêÏùÑ Î∞òÌôòÌïòÍ≥† Î©îÎ™®Î¶¨Î•º ÌôïÎ≥¥Ìï©ÎãàÎã§.\n","#@markdown ---\n","\n","import gc\n","from numba import cuda\n","\n","try:\n","  if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","\n","  del vgg_encoder\n","  del vgg_output\n","\n","  gc.collect()\n","\n","  print(\"Clear!\")\n","\n","except:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"lTh4n74OlzY5","executionInfo":{"status":"ok","timestamp":1709025116641,"user_tz":-540,"elapsed":908,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"b176263c-1a1a-4881-c30c-f4ca31c51d87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Clear!\n"]}]},{"cell_type":"code","source":["cfg.models.encoder._target_ = cfg.encoder_path + '.vgg16.VGG16'\n","del cfg.models.encoder.model_name\n","del cfg.models.encoder.select_features\n","del cfg.models.encoder.pretrained\n","\n","with torch.no_grad():\n","  encoder = instantiate(cfg.models.encoder).to(device)\n","  encoder_features = encoder(data_loaded[\"images\"])\n","  for encoder_feature in encoder_features:\n","      print(f'encoder feature shape: {encoder_feature.shape}')\n","\n","  cfg.models.decoder.in_channels = [64, 128, 256, 512, 512]\n","  cfg.models.decoder.strides = [2, 4, 8, 16, 32]\n","  decoder = instantiate(cfg.models.decoder).to(device)\n","  decoder_features = decoder(encoder_features)\n","  for decoder_feature in decoder_features:\n","      print(f'decoder feature shape: {decoder_feature.shape}')"],"metadata":{"id":"n1NPMY2zY9g8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709025134886,"user_tz":-540,"elapsed":796,"user":{"displayName":"Sangjoon Han","userId":"10245612847654687799"}},"outputId":"0017afe4-2ea7-4c23-ac71-02a1261ab8c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["encoder feature shape: torch.Size([4, 64, 320, 320])\n","encoder feature shape: torch.Size([4, 128, 160, 160])\n","encoder feature shape: torch.Size([4, 256, 80, 80])\n","encoder feature shape: torch.Size([4, 512, 40, 40])\n","encoder feature shape: torch.Size([4, 512, 20, 20])\n","decoder feature shape: torch.Size([4, 256, 320, 320])\n","decoder feature shape: torch.Size([4, 256, 320, 320])\n","decoder feature shape: torch.Size([4, 256, 320, 320])\n","decoder feature shape: torch.Size([4, 256, 320, 320])\n","decoder feature shape: torch.Size([4, 256, 320, 320])\n"]}]}]}