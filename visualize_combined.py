#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GT (Ground Truth)ì™€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë™ì‹œì— í•œ ì´ë¯¸ì§€ì— ì‹œê°í™”
GT: íŒŒë‘ìƒ‰ í´ë¦¬ê³¤
ì˜ˆì¸¡: ë…¹ìƒ‰ í´ë¦¬ê³¤

ì‚¬ìš©ë²•:
python3 visualize_combined.py --exp_name hrnet_w44.ms_in1k_1024_brcn_roate_1013_203259 --num_images 10
"""

import json
import os
import argparse
from pathlib import Path
import cv2
import numpy as np

def load_gt_and_prediction(exp_name):
    """
    GTì™€ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
    """
    # GT JSON ê²½ë¡œ ì°¾ê¸°
    jsons_dir = Path('data/datasets/jsons')
    gt_files = list(jsons_dir.glob('*val*.json')) + list(jsons_dir.glob('*.json'))
    if gt_files:
        gt_file = gt_files[0]  # ì²« ë²ˆì§¸ ì°¾ì€ ê²ƒ ì‚¬ìš©
    else:
        print("GT JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
    prediction_dir = Path('outputs') / exp_name / 'predictions'
    if not prediction_dir.exists():
        print(f"ì˜ˆì¸¡ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prediction_dir}")
        return None, None

    prediction_files = list(prediction_dir.glob('*.json'))
    if not prediction_files:
        print(f"ì˜ˆì¸¡ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ in {prediction_dir}")
        return None, None

    prediction_file = max(prediction_files, key=lambda p: p.stat().st_mtime)

    print(f"GT íŒŒì¼: {gt_file}")
    print(f"ì˜ˆì¸¡ íŒŒì¼: {prediction_file}")

    # GT ë¡œë“œ ë° ë³€í™˜ (words -> ì‹œê°í™” í¬ë§·)
    with open(gt_file, 'r', encoding='utf-8') as f:
        gt_raw_data = json.load(f)

    # GT ë³€í™˜ (images -> filename format)
    gt_data = {}
    if 'images' in gt_raw_data:
        for image_filename, image_data in gt_raw_data['images'].items():
            gt_data[image_filename] = []
            if 'words' in image_data:
                for word_id, word_data in image_data['words'].items():
                    if 'points' in word_data:
                        gt_data[image_filename].append({
                            'text_regions': [{'points': word_data['points']}]
                        })

    # ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ ë° ë³€í™˜
    with open(prediction_file, 'r', encoding='utf-8') as f:
        prediction_data = json.load(f)

    # ì˜ˆì¸¡ ê²°ê³¼ ë³€í™˜ (ëŒ€íšŒ í¬ë§· -> ì‹œê°í™” í¬ë§·)
    predictions = {}
    if 'images' in prediction_data:
        for image_filename, image_data in prediction_data['images'].items():
            predictions[image_filename] = []
            if 'words' in image_data:
                for word_id, word_data in image_data['words'].items():
                    if 'points' in word_data:
                        predictions[image_filename].append({
                            'text_regions': [{'points': word_data['points']}]
                        })

    return gt_data, predictions

def visualize_combined(image_path, gt_data, prediction_data, output_path, image_filename):
    """
    GTì™€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë™ì‹œì— ì‹œê°í™”
    GT: íŒŒë‘ìƒ‰, ì˜ˆì¸¡: ë…¹ìƒ‰
    """
    # ì´ë¯¸ì§€ ì½ê¸°
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return

    # GT í´ë¦¬ê³¤ ê·¸ë¦¬ê¸° (íŒŒë‘ìƒ‰)
    if image_filename in gt_data and gt_data[image_filename]:
        for annotation in gt_data[image_filename]:
            if 'text_regions' in annotation and annotation['text_regions']:
                points = np.array(annotation['text_regions'][0]['points'], dtype=np.int32).reshape((-1, 1, 2))

                # íŒŒë‘ìƒ‰, 2px ì„  êµµê¸°
                cv2.polylines(image, [points], True, (255, 0, 0), 2)  # GT: Blue (BGR: (255, 0, 0))

    # ì˜ˆì¸¡ í´ë¦¬ê³¤ ê·¸ë¦¬ê¸° (ë…¹ìƒ‰)
    if image_filename in prediction_data and prediction_data[image_filename]:
        for prediction in prediction_data[image_filename]:
            if 'text_regions' in prediction and prediction['text_regions']:
                for region in prediction['text_regions']:
                    points = np.array(region['points'], dtype=np.int32).reshape((-1, 1, 2))

                    # ë…¹ìƒ‰, 2px ì„  êµµê¸°
                    cv2.polylines(image, [points], True, (0, 180, 0), 2)  # ì˜ˆì¸¡: Green (BGR: (0, 180, 0))

    # ë²”ë¡€ ì¶”ê°€ (ìƒë‹¨ ì™¼ìª½)
    legend_x, legend_y = 10, 30
    cv2.rectangle(image, (legend_x, legend_y), (legend_x+250, legend_y+50), (255, 255, 255), -1)  # ë°°ê²½
    cv2.rectangle(image, (legend_x+5, legend_y+10), (legend_x+20, legend_y+25), (255, 0, 0), -1)  # íŒŒë‘ìƒ‰ ì‚¬ê°í˜•
    cv2.rectangle(image, (legend_x+125, legend_y+10), (legend_x+140, legend_y+25), (0, 180, 0), -1)  # ë…¹ìƒ‰ ì‚¬ê°í˜•
    cv2.putText(image, "GT (Blue)", (legend_x+25, legend_y+22), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1)
    cv2.putText(image, "Prediction (Green)", (legend_x+145, legend_y+22), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 100, 0), 1)

    # ì¶œë ¥ í´ë” ìƒì„±
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # ì´ë¯¸ì§€ ì €ì¥
    success = cv2.imwrite(str(output_path), image)
    if success:
        print(f"í†µí•© ì‹œê°í™” ì €ì¥: {output_path}")
    else:
        print(f"ì €ì¥ ì‹¤íŒ¨: {output_path}")

def main():
    parser = argparse.ArgumentParser(description="GTì™€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë™ì‹œì— ì‹œê°í™”")
    parser.add_argument('--exp_name', type=str, required=True,
                       help='ì‹¤í—˜ ì´ë¦„ (ì˜ˆ: hrnet_w44.ms_in1k_1024_brcn_roate_1013_203259)')
    parser.add_argument('--num_images', type=int, default=None,
                       help='ì‹œê°í™”í•  ì´ë¯¸ì§€ ê°œìˆ˜ (ê¸°ë³¸: None, ì „ì²´ val ì´ë¯¸ì§€ ì²˜ë¦¬)')

    args = parser.parse_args()

    exp_name = args.exp_name
    num_images = args.num_images

    # ê²½ë¡œ ì„¤ì •
    images_dir = Path('data/datasets/images/val')
    output_dir = Path('visualized_combined') / exp_name

    print(f"ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {images_dir}")
    if images_dir.exists():
        print(f"ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(list(images_dir.glob('*.jpg')))}")

    # GTì™€ ì˜ˆì¸¡ ë°ì´í„° ë¡œë“œ
    gt_data, prediction_data = load_gt_and_prediction(exp_name)
    if gt_data is None or prediction_data is None:
        print("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return

    print(f"GT ì´ë¯¸ì§€ ìˆ˜: {len(gt_data)}")
    print(f"ì˜ˆì¸¡ ì´ë¯¸ì§€ ìˆ˜: {len(prediction_data)}")
    if num_images is None:
        num_images = len(gt_data)  # ì „ì²´ ì´ë¯¸ì§€ ì²˜ë¦¬
    print(f"ì‹œê°í™”í•  ì´ë¯¸ì§€ ìˆ˜: {min(num_images, len(gt_data), len(prediction_data))}")

    # ê³µí†µ ì´ë¯¸ì§€ ì°¾ê¸° ë° ì‹œê°í™”
    processed_count = 0
    for image_filename in gt_data.keys():
        if image_filename in prediction_data and processed_count < num_images:
            image_path = images_dir / image_filename
            if not image_path.exists():
                continue

            output_path = output_dir / image_filename
            visualize_combined(image_path, gt_data, prediction_data, output_path, image_filename)
            processed_count += 1

    print(f"\nì™„ë£Œ! {processed_count}ê°œ ì´ë¯¸ì§€ í†µí•© ì‹œê°í™”ë¨")
    print(f"ê²°ê³¼ í´ë”: {output_dir}")
    print("\nìƒ‰ìƒ êµ¬ë¶„:")
    print("ğŸŸ¦ íŒŒë‘ìƒ‰ í´ë¦¬ê³¤: GT (Ground Truth - ì •ë‹µ)")
    print("ğŸŸ© ë…¹ìƒ‰ í´ë¦¬ê³¤: Prediction (ì˜ˆì¸¡ ê²°ê³¼)")

if __name__ == "__main__":
    main()
